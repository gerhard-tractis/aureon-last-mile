---
stepsCompleted: [1, 2, 3, 4]
inputDocuments:
  - "_bmad-output/planning-artifacts/prd.md"
  - "_bmad-output/planning-artifacts/architecture.md"
  - "_bmad-output/planning-artifacts/ux-design-specification.md"
  - "_bmad-output/planning-artifacts/mockups/pickup-verification-mobile.html"
  - "_bmad-output/planning-artifacts/mockups/business-owner-dashboard-desktop.html"
  - "_bmad-output/planning-artifacts/mockups/operations-control-center-desktop.html"
  - "_bmad-output/planning-artifacts/mockups/operations-control-center-mobile.html"
---

# Aureon_Last_Mile - Epic Breakdown

## Overview

This document provides the complete epic and story breakdown for Aureon_Last_Mile, decomposing the requirements from the PRD, UX Design, and Architecture into implementable stories.

## Requirements Inventory

### Functional Requirements

**Data Management & Business Intelligence**

**FR1**: Business owners can view real-time customer volume analysis showing orders per day per retailer

**FR2**: Business owners can view geographic heatmap showing order distribution by comuna/district

**FR3**: Business owners can track capacity utilization (forecast vs actual orders) per retailer

**FR4**: Business owners can view shortage claim costs broken down by customer, location, and time period

**FR5**: Business owners can track SLA performance metrics (on-time delivery percentage, delivery success rate)

**FR6**: Business owners can export operational and financial reports in CSV/PDF format for presentations and contract negotiations

**FR7**: Operations managers can view real-time operational monitoring dashboards showing capacity, pickup status, and inventory levels

**FR8**: The system can ingest order data from email manifests (automated parsing from attachments)

**FR9**: The system can ingest order data from manual CSV/Excel uploads

**FR10**: The system can ingest order data from retailer APIs (Falabella, Shopee, Mercado Libre) via real-time webhooks or polling

**FR11**: The system can store historical order data for trend analysis and contract negotiations

**Pickup Verification & Manifests**

**FR12**: Pickup crew can view their assigned pickup manifests on mobile devices

**FR13**: Pickup crew can scan package barcodes/QR codes using mobile device camera

**FR14**: Pickup crew can see real-time verification status (verified vs pending) with progress tracking during pickup

**FR15**: The system can detect and alert pickup crew when scanned packages don't match the manifest

**FR16**: Pickup crew can capture digital signatures (touch/mouse) to confirm pickup completion

**FR17**: The system can generate PDF receipts showing complete pickup audit trail (timestamp, user, discrepancies, signature)

**FR18**: Pickup crew can work offline (scan locally) and sync data when connection is restored

**FR19**: The system can reconcile pickup discrepancies and log them for shortage claim prevention

**Hub Reception & Chain of Custody**

**FR20**: Warehouse staff can scan packages during hub reception to log arrival

**FR21**: The system can automatically reconcile received packages against signed pickup manifests and alert discrepancies

**FR22**: Warehouse staff can distinguish between retailer shortages (never received) and internal handling issues

**FR23**: The system can log all hub reception activities with timestamp, user, and operator context for accountability

**Warehouse & Inventory Management**

**FR24**: Warehouse staff can assign packages to specific physical locations (docks, zones, shelves, staging areas) via barcode scanning

**FR25**: Warehouse staff can track package movements between locations with full audit trail

**FR26**: Warehouse staff can search for package locations in real-time by order number

**FR27**: The system can provide location history for packages to support theft investigation (last scan location + timestamp)

**FR28**: Warehouse staff can view reconciliation reports comparing signed manifests vs received inventory

**Loading & Route Management**

**FR29**: Loading supervisors can view all orders assigned to specific delivery zones/trucks

**FR30**: Loading supervisors can assign orders to delivery zones based on sectorization rules (comuna/district mappings)

**FR31**: The system can enforce sectorization rules and alert when orders are assigned to incorrect zones

**FR32**: Loading supervisors can override sectorization errors with manual reassignment when needed

**FR33**: Loading crew can scan packages during truck loading to confirm load completion

**FR34**: Loading crew can view real-time loading progress per truck (X of Y packages loaded)

**FR35**: Loading supervisors can mark trucks as loaded and ready for departure

**FR36**: The system can automatically create routes in operator's preferred last-mile tool (SimpliRoute, Beetrack, Driv.in) via API after loading completion

**FR37**: Loading supervisors can configure loading workflows based on hub layout (immediate scan-and-load vs batch scanning)

**Capacity Planning & Forecasting**

**FR38**: Operations managers can view real-time order visibility showing incoming orders from retailer e-commerce systems

**FR39**: Operations managers can receive automated alerts when retailers approach or exceed agreed capacity limits

**FR40**: The system can track retailer forecast accuracy (predicted vs actual order volumes) over time

**FR41**: Operations managers can plan resources 1-2 days in advance based on real-time order forecasts

**Integration & API Management**

**FR42**: The system can integrate with retailer e-commerce platforms (Falabella, Shopee, Mercado Libre, Ripley, Paris) to receive real-time order data

**FR43**: The system can integrate with last-mile routing tools (SimpliRoute, Beetrack, Driv.in) to push routes and receive delivery status updates

**FR44**: The system can receive delivery status updates from last-mile tools via webhooks

**FR45**: The system can transform delivery status data to each retailer's required JSON format and push updates to retailer systems

**FR46**: Admin users can configure retailer API integrations (endpoints, authentication, data mapping) without custom coding

**FR47**: The system can gracefully degrade to email manifest parsing when retailer APIs are unavailable

**FR48**: External retailer developers can access Aureon's public API documentation portal with authentication guides, endpoints, schemas, and code examples

**FR49**: External retailer developers can test integrations in a sandbox environment with test credentials

**User & Access Management**

**FR50**: Admins can create and manage user accounts for all roles (pickup crew, warehouse staff, loading crew, operations managers, admins)

**FR51**: The system can enforce role-based permissions preventing users from accessing unauthorized features

**FR52**: Pickup crew can only access pickup verification features on mobile devices

**FR53**: Warehouse staff can only access warehouse and inventory features

**FR54**: Loading crew can only access loading workflow features

**FR55**: Operations managers can access operational dashboards and reports but cannot modify configurations

**FR56**: Admins can access all features including BI dashboards, configuration management, and user administration

**FR57**: Users can authenticate via JWT-based login with secure session management

**FR58**: The system can enforce tenant isolation ensuring operators cannot access other operators' data

**Support & Troubleshooting**

**FR59**: Operators can submit support queries to the AI support agent (Claude Code) via natural language chat

**FR60**: The AI support agent can query audit logs, order history, and system diagnostics to investigate issues

**FR61**: The AI support agent can provide troubleshooting recommendations for common issues (missing packages, API failures, discrepancies)

**FR62**: The AI support agent can escalate complex issues to human Aureon support team when unable to resolve

**FR63**: The AI support agent can recommend security camera footage timestamps based on package location audit trails

**FR64**: Operations managers can view audit logs for troubleshooting operational issues

**Platform Administration (Aureon DevOps)**

**FR65**: Aureon DevOps can provision new operator tenants with environment configurations (hub layouts, sectorization rules, integration settings)

**FR66**: Aureon DevOps can configure retailer API integrations (endpoints, authentication tokens, data mapping) for operators

**FR67**: Aureon DevOps can monitor platform health (uptime, performance, error rates) via real-time dashboards

**FR68**: Aureon DevOps can access customer usage analytics (active users, API volume, feature adoption) for all operators

**FR69**: The system can alert Aureon DevOps when SLA thresholds are breached (uptime, response time)

**FR70**: Aureon DevOps can manage infrastructure scaling (database replicas, API servers, CDN)

**Multi-Tenant & Subscription Management**

**FR71**: The system can isolate operator data using PostgreSQL Row-Level Security policies

**FR72**: Admins can configure operator-specific settings (sectorization rules, hub layout, branding)

**FR73**: The system can track operator subscription tier (Starter, Growth, Enterprise) and enforce usage limits (order capacity, user count, integration count)

**FR74**: The system can calculate overage charges when operators exceed tier limits (orders, users, integrations)

**FR75**: Admins can view subscription billing history and upcoming charges

**Sectorization & Routing Intelligence**

**FR76**: Admins can define sectorization rules mapping comunas/districts to delivery zones

**FR77**: The system can validate order zone assignments against sectorization rules and prevent allocation errors

**FR78**: Loading supervisors can view suggested zone assignments based on address and sectorization rules

**Audit & Compliance**

**FR79**: The system can log all data access with user_id, operator_id, timestamp, action, and IP address

**FR80**: Admins can review audit trails for security investigations and compliance requirements

**FR81**: The system can retain audit logs for 7 years per Chilean commercial law requirements

**FR82**: The system can encrypt sensitive data (API credentials, retailer authentication tokens) at rest with operator-specific encryption keys

### Non-Functional Requirements

**Performance**

**NFR-P1: Page Load Performance**
- BI dashboard initial load: â‰¤2 seconds on 10 Mbps broadband connection
- Operational screens (pickup, warehouse, loading): â‰¤1.5 seconds on mobile 4G connection
- Chart/widget rendering: â‰¤500ms per widget

**NFR-P2: API Response Time**
- Read operations (GET requests): â‰¤200ms p95, â‰¤500ms p99
- Write operations (POST/PUT/PATCH): â‰¤500ms p95, â‰¤1s p99
- Bulk operations (manifest processing): â‰¤5 seconds per 100 orders

**NFR-P3: Concurrent User Support**
- System must support 100+ concurrent users across all operators without performance degradation
- Individual operator must support 20+ concurrent users during peak operations (Cyberdays, Black Friday)

**NFR-P4: Database Query Performance**
- Order search/lookup queries: â‰¤300ms
- BI aggregation queries: â‰¤2 seconds for standard date ranges (7 days), â‰¤10 seconds for extended ranges (90 days)
- Real-time inventory location queries: â‰¤200ms

**NFR-P5: Mobile Application Performance**
- Barcode scan processing: â‰¤100ms per scan
- Offline sync on reconnection: â‰¤30 seconds for 500 records
- Mobile app startup: â‰¤3 seconds

**Security**

**NFR-S1: Data Encryption**
- All data in transit encrypted with TLS 1.3 (minimum)
- All sensitive data at rest encrypted with AES-256
- Operator-specific encryption keys for API credentials and retailer authentication tokens

**NFR-S2: Multi-Tenant Isolation**
- PostgreSQL Row-Level Security (RLS) policies enforced at database level for 100% tenant data isolation
- No operator can access another operator's data through any API endpoint, database query, or system interface
- All database queries automatically filtered by tenant_id via RLS policies

**NFR-S3: Authentication & Authorization**
- JWT-based authentication with token expiration â‰¤24 hours
- Role-based access control (RBAC) enforced at API and UI layers
- Password requirements: minimum 12 characters, complexity rules enforced
- Failed login lockout: 5 attempts trigger 15-minute account lockout

**NFR-S4: API Security**
- Rate limiting: 1000 requests per minute per operator, 100 requests per minute per user
- API authentication via Bearer tokens with expiration
- CORS policies restrict origins to authorized domains only

**NFR-S5: Audit & Compliance**
- All data access logged with user_id, operator_id, timestamp, action, IP address
- Audit logs retained for 7 years per Chilean commercial law
- PII and sensitive data access logged separately with enhanced detail
- Quarterly security audits of RLS policies and access logs

**NFR-S6: Data Protection**
- Automated daily backups with 30-day retention
- Backup encryption with separate key management
- Disaster recovery plan with defined RTO/RPO

**Scalability**

**NFR-SC1: Operator Growth**
- System must scale from 1 operator (MVP launch) to 50+ operators within 12 months without architectural changes
- New operator provisioning time: â‰¤4 hours (including tenant setup, configuration, user creation)

**NFR-SC2: Order Volume Scaling**
- System must handle 4x peak load spikes (e.g., Cyberdays events) without manual intervention
- Starter tier: Support up to 5,000 orders/month per operator
- Growth tier: Support up to 50,000 orders/month per operator
- Enterprise tier: Support 100,000+ orders/month per operator

**NFR-SC3: Database Scalability**
- PostgreSQL database optimized for multi-tenant queries with appropriate indexing on tenant_id + common filter fields
- Database connection pooling configured to support 100+ concurrent connections
- Query execution plans reviewed quarterly to optimize performance as data grows

**NFR-SC4: Auto-Scaling**
- API servers auto-scale horizontally based on CPU utilization (target 70% average)
- Minimum 2 API server instances for redundancy
- Database read replicas provisioned when read load exceeds 60% of primary capacity

**NFR-SC5: Integration Scaling**
- System must support up to 10 retailer integrations per operator without performance degradation
- Webhook/API call queuing to handle burst traffic from retailers (e.g., daily manifest drops)

**Reliability**

**NFR-R1: System Uptime**
- Starter tier: 99% uptime SLA (maximum 7.3 hours downtime per month)
- Growth tier: 99.9% uptime SLA (maximum 43 minutes downtime per month)
- Enterprise tier: 99.95% uptime SLA (maximum 22 minutes downtime per month)

**NFR-R2: Disaster Recovery**
- Recovery Time Objective (RTO): â‰¤4 hours for critical services (order processing, BI dashboards, operational workflows)
- Recovery Point Objective (RPO): â‰¤15 minutes for transactional data (orders, inventory, manifests)

**NFR-R3: Data Integrity**
- Zero data loss tolerance for committed transactions (orders, manifests, inventory updates)
- Automated database integrity checks daily
- Referential integrity enforced via foreign key constraints

**NFR-R4: Error Handling & Resilience**
- All user-facing errors display actionable error messages (not generic "Error 500")
- Failed background jobs (manifest processing, retailer sync) automatically retry with exponential backoff (3 retries over 15 minutes)
- System degrades gracefully when dependencies fail (e.g., retailer APIs down â†’ queue for retry, allow manual manifest entry)

**NFR-R5: Monitoring & Alerting**
- Real-time monitoring of API response times, error rates, database performance
- Automated alerts to DevOps when error rate exceeds 1% over 5-minute window, API response time p95 exceeds 1 second, database connections exceed 80% capacity, disk space below 20% free

**NFR-R6: Backup & Recovery**
- Automated daily database backups with 30-day retention
- Ability to restore from backup within 2 hours
- Monthly backup restoration testing to validate recovery procedures

**Integration**

**NFR-I1: External API Reliability**
- Retailer API integrations must maintain 99%+ uptime from Aureon's perspective (excluding retailer downtime)
- Failed API calls automatically queued for retry (3 attempts over 30 minutes with exponential backoff)

**NFR-I2: Graceful Degradation**
- When retailer APIs are unavailable, system falls back to email manifest parsing
- When email parsing fails, system allows manual manifest entry
- Integration failures do not block critical operational workflows (pickup verification, warehouse operations can continue offline)

**NFR-I3: API Versioning**
- Public APIs versioned (e.g., /v1/, /v2/) to prevent breaking changes for external integrations
- Deprecated API versions supported for minimum 12 months with migration notices

**NFR-I4: Data Synchronization**
- Order status updates pushed to retailer systems within 5 minutes of status change
- If push fails, retry queue processes updates until successful delivery or manual intervention required (after 24 hours)

**NFR-I5: Integration Testing**
- Sandbox environment provided for retailer developers to test integrations
- Automated integration tests run nightly to detect API contract changes or failures

**NFR-I6: Third-Party Dependencies**
- External dependencies (email services, SMS providers, map services) have fallback providers configured
- Critical features do not depend on single points of failure for third-party services

### Additional Requirements

**From Architecture Document:**

**Starter Template & Technology Foundation:**
- **CRITICAL - Epic 1 Story 1**: Use Razikus Supabase-Next.js Template as the foundation for the project
- Technology Stack: Next.js 14 App Router, TypeScript, Supabase PostgreSQL, Vercel (frontend hosting), Railway (backend + workers)
- PWA Enhancement Layer: Serwist for service workers, IndexedDB via Dexie for offline storage, Background Sync API for automatic upload when connectivity restored
- Multi-tenant isolation using PostgreSQL Row-Level Security (RLS) policies enforced at database level
- Authentication via Supabase Auth with JWT tokens (24-hour expiration) and role-based access control
- Audit log pattern for all data operations (user_id, operator_id, timestamp, action, IP address)
- Soft delete pattern for all main tables (deleted_at column) to enable recovery
- Raw + normalized data storage for retailer orders (store original JSON/CSV + parsed data)

**Infrastructure & Deployment:**
- Frontend deployment on Vercel with automatic Git deployments and preview URLs per PR
- Backend + workers on Railway with built-in Redis, BullMQ for background jobs, n8n for workflow orchestration
- Database + services on Supabase (PostgreSQL, Auth, Realtime, Storage, Edge Functions)
- CI/CD pipeline via GitHub Actions (CI: test, type-check, lint, build on every commit; CD: manual deployment for cost control)
- Environment configuration: Development (local), Preview (per PR), Production

**Caching Strategy (Multi-Layer):**
- Layer 1 - Frontend (TanStack Query): Dashboard metrics 30s stale/60s refresh, customer lists 5min, order details 1min
- Layer 2 - API (Redis on Railway): SLA calculations 5min TTL, customer lists 15min TTL, sectorization rules 1hr TTL
- Layer 3 - CDN (Vercel): Static assets cached forever with hash-based invalidation, HTML no cache
- Layer 4 - Offline (Service Worker + IndexedDB): App shell cached forever, scan queue until synced, current manifest until complete

**Monitoring & Error Tracking:**
- Error tracking via Sentry (5,000 errors/month free tier) with stack traces, error grouping, release tracking
- Performance monitoring via Vercel Analytics (page load, Core Web Vitals), Railway Dashboard (CPU, memory, API response), Supabase Dashboard (query performance, connections)
- Uptime monitoring via BetterStack or UptimeRobot (check every 5 minutes, email/SMS alerts)
- Structured JSON logging with request_id, operator_id, user_id, timestamp (30-day retention on Railway)
- Alert rules: Critical (app downtime >5min, error rate >5%, DB connections >90%), Warning (API p95 >1s, failed jobs >10/hr, disk >80%), Info (new signups, integration failures, usage approaching limits)

**API & Communication:**
- REST API pattern with standard HTTP methods (GET, POST, PUT, DELETE) for universal compatibility
- OpenAPI/Swagger documentation for developer experience and AI agent integration
- Rate limiting: 1000 requests/min per operator, 100 requests/min per user
- API versioning (/v1/, /v2/) with 12-month deprecation support

**Database Patterns:**
- Supabase Migrations for version-controlled schema changes with rollback support
- Multi-tenant isolation: Every table includes operator_id, RLS policies enforce tenant filtering
- Database connection pooling for 100+ concurrent connections
- Indexing on tenant_id + common filter fields for query performance

**From UX Design Specification:**

**Mobile-First Operational Design:**
- Primary operational users (pickup crews, warehouse staff, loading crews) use mobile devices (smartphones/tablets) with RF barcode scanners
- Offline-first architecture: All scanning workflows must function without connectivity and sync when connection restored
- Multi-sensory feedback for every scan: Beep sound + vibration + visual confirmation (green flash for success, red overlay for error)
- Large touch targets: Minimum 44px for all interactive elements to support gloved hands and outdoor conditions
- High contrast UI for outdoor visibility in varying lighting conditions
- Progressive adoption support: Training mode vs production mode, confidence indicators, parallel workflow support during transition

**Responsive & Multi-Device:**
- Smartphone UI: Compact, thumb-friendly for pickup crews (primary operational interface)
- Tablet UI: Larger workspace for warehouse supervisors
- Desktop UI: Full dashboards for management with 1440px+ optimization
- Consistent workflows and data across all device types

**Interaction Patterns:**
- RF scanner + touchscreen integration with instant validation feedback (<100ms scan processing per NFR-P5)
- Real-time progress indicators ("You've verified 287/300 orders, 0 discrepancies detected")
- Context-aware error messages ("This order belongs to Yard B, not Yard A" not generic "Error")
- Intelligent validation to prevent costly mistakes while maintaining workflow speed

**Cultural & Localization:**
- Primary language: Spanish (Chilean logistics terminology: comuna, bodega, reparto, indemnizaciÃ³n)
- Potential bilingual support (espaÃ±ol/inglÃ©s) for management reporting

**From Mockup Specifications:**

**Pickup Verification Mobile (3-Screen Workflow):**
- Screen 1 - Manifest List: Display today's pickups (customer, order count, location, time, status), tap to select and start verification
- Screen 2 - Scanning: Real-time progress bar (0/347 â†’ 347/347), large scan area with animation, success feedback (green flash + beep), error feedback (red overlay + triple beep), offline indicator support
- Screen 3 - Completion: Summary stats (orders verified, time, discrepancies, precision), generate digital receipt button, return to manifest list
- Pattern applies to: Loading and Hub Reception workflows (same UX pattern)

**Business Owner Dashboard Desktop:**
- Hero SLA section: 94.2% with color coding, trend indicator (+2.3%), progress bar visualization
- Primary metrics cards: FADR (First Attempt Delivery Rate), Claims (shortage costs in CLP), Efficiency (average time)
- Customer performance table: Sortable columns (Cliente, Pedidos, SLA %, FADR %, Fallos, Valor), color-coded SLA indicators (green/yellow/red), export CSV functionality
- Failed deliveries analysis: Bar chart for top 5 failure reasons with percentages, line chart for trend over time (Chart.js), peak/lowest insights
- Secondary metrics: Capacity utilization, orders per hour, cost per delivery, customer satisfaction rating
- Actions bar: Export report, send to retailers, configure settings

**Operations Control Center Desktop:**
- Collapsible sidebar navigation (70px collapsed â†’ 250px expanded): Hover to expand with labels, click to lock expanded, navigate between sections (Ops Control, Business Dashboard, Inventory, Fleet, Team, Reports, Settings), current section highlighted in Tractis gold (#e6c15c)
- Operations view: Pipeline overview with real-time order counts across 8 stages, compact cards visible without scrolling, detailed orders table with status indicators, delivery promise dates and time windows, interactive filters and search
- Screen size optimization: 1440px+ displays

**Operations Control Center Mobile:**
- Bottom tab bar navigation (60px from bottom for thumb optimization): 5 tabs (ðŸ“Š Ops, ðŸ’° Dashboard, ðŸ“¦ Orders, ðŸ“ˆ Reports, âš™ï¸ More), active tab highlighted in Tractis gold, badge indicator on Ops tab for urgent items, tap to switch sections with header title update
- Operations view: Phone-sized viewport (428px max-width), card-based layout for touch, status summary cards (Urgent/Alert/OK), essential order information at a glance, swipe gestures and pull-to-refresh support

**Design System (Tractis Theme):**
- Colors: Gold primary #e6c15c, Slate palette #f8fafc to #0f172a, status colors (red urgent, yellow alert, green ok, gray late)
- Typography: Inter Variable font family
- Component library: shadcn/ui components integrated with Tractis theme

### FR Coverage Map

**MVP Scope - 47 FRs Covered Across 5 Epics**

**Epic 1: Platform Foundation & Multi-Tenant SaaS Setup**
- Starter Template: Razikus Supabase-Next.js Template + PWA Enhancement Layer
- FR50: Admins can create and manage user accounts for all roles
- FR51: The system can enforce role-based permissions preventing users from accessing unauthorized features
- FR52: Pickup crew can only access pickup verification features on mobile devices
- FR53: Warehouse staff can only access warehouse and inventory features
- FR54: Loading crew can only access loading workflow features
- FR55: Operations managers can access operational dashboards and reports but cannot modify configurations
- FR56: Admins can access all features including BI dashboards, configuration management, and user administration
- FR57: Users can authenticate via JWT-based login with secure session management
- FR58: The system can enforce tenant isolation ensuring operators cannot access other operators' data
- FR65: Aureon DevOps can provision new operator tenants with environment configurations
- FR66: Aureon DevOps can configure retailer API integrations for operators
- FR71: The system can isolate operator data using PostgreSQL Row-Level Security policies
- FR72: Admins can configure operator-specific settings (sectorization rules, hub layout, branding)
- FR79: The system can log all data access with user_id, operator_id, timestamp, action, and IP address
- FR80: Admins can review audit trails for security investigations and compliance requirements
- FR81: The system can retain audit logs for 7 years per Chilean commercial law requirements
- FR82: The system can encrypt sensitive data at rest with operator-specific encryption keys

**Epic 2: Order Data Ingestion**
- FR8: The system can ingest order data from email manifests (automated parsing from attachments)
- FR9: The system can ingest order data from manual CSV/Excel uploads
- FR10: The system can ingest order data from retailer APIs via real-time webhooks or polling
- FR47: The system can gracefully degrade to email manifest parsing when retailer APIs are unavailable

**Epic 3: Business Intelligence Dashboard**
- FR1: Business owners can view real-time customer volume analysis showing orders per day per retailer
- FR2: Business owners can view geographic heatmap showing order distribution by comuna/district
- FR3: Business owners can track capacity utilization (forecast vs actual orders) per retailer
- FR4: Business owners can view shortage claim costs broken down by customer, location, and time period
- FR5: Business owners can track SLA performance metrics (on-time delivery percentage, delivery success rate)
- FR6: Business owners can export operational and financial reports in CSV/PDF format
- FR7: Operations managers can view real-time operational monitoring dashboards
- FR11: The system can store historical order data for trend analysis and contract negotiations

**Epic 4: Pickup Verification Mobile PWA**
- FR12: Pickup crew can view their assigned pickup manifests on mobile devices
- FR13: Pickup crew can scan package barcodes/QR codes using mobile device camera
- FR14: Pickup crew can see real-time verification status with progress tracking during pickup
- FR15: The system can detect and alert pickup crew when scanned packages don't match the manifest
- FR16: Pickup crew can capture digital signatures to confirm pickup completion
- FR17: The system can generate PDF receipts showing complete pickup audit trail
- FR18: Pickup crew can work offline and sync data when connection is restored
- FR19: The system can reconcile pickup discrepancies and log them for shortage claim prevention

**Epic 5: Operations Control Center**
- FR38: Operations managers can view real-time order visibility showing incoming orders from retailer e-commerce systems
- FR39: Operations managers can receive automated alerts when retailers approach or exceed agreed capacity limits
- FR40: The system can track retailer forecast accuracy (predicted vs actual order volumes) over time
- FR41: Operations managers can plan resources 1-2 days in advance based on real-time order forecasts
- FR64: Operations managers can view audit logs for troubleshooting operational issues
- FR67: Aureon DevOps can monitor platform health (uptime, performance, error rates) via real-time dashboards
- FR68: Aureon DevOps can access customer usage analytics (active users, API volume, feature adoption)
- FR69: The system can alert Aureon DevOps when SLA thresholds are breached
- FR70: Aureon DevOps can manage infrastructure scaling

**Post-MVP FRs (Not in Current Scope): 35 FRs**
- Hub Reception & Chain of Custody: FR20-FR23
- Warehouse & Inventory Management: FR24-FR28
- Loading & Route Management: FR29-FR37
- Retailer & Last-Mile Integrations: FR42-FR46, FR48-FR49
- Sectorization & Routing Intelligence: FR76-FR78
- Subscription & Tenant Management: FR73-FR75
- AI-Powered Support Agent: FR59-FR63

## Epic List

**MVP Scope: 5 Epics for 4-Week Implementation Timeline**

### Epic 1: Platform Foundation & Multi-Tenant SaaS Setup

Aureon DevOps can provision secure, isolated operator tenants with complete authentication, role-based access control, and audit infrastructure on a production-ready tech stack.

**FRs covered:** Starter Template (Architecture), FR50-FR58, FR65-FR66, FR71-FR72, FR79-FR82 (19 FRs)

**Technical Foundation:**
- Razikus Supabase-Next.js Template (Next.js 14 App Router, TypeScript)
- PWA Enhancement Layer (Serwist service workers, IndexedDB via Dexie, Background Sync API)
- Multi-tenant isolation via PostgreSQL Row-Level Security (RLS) policies
- Supabase Auth with JWT tokens (24-hour expiration) + RBAC
- Audit log pattern (user_id, operator_id, timestamp, action, IP address)
- Soft delete pattern for data recovery
- Deployment: Vercel (frontend) + Railway (backend + Redis + BullMQ) + Supabase (database + auth)
- CI/CD: GitHub Actions (CI on every commit: test, lint, build; CD: manual deployment)
- Monitoring: Sentry (error tracking), BetterStack (uptime), structured JSON logging

---

### Epic 2: Order Data Ingestion

Operations managers can import retailer orders into the platform via email manifests, CSV uploads, or manual entry with graceful fallback mechanisms.

**FRs covered:** FR8-FR10, FR47 (4 FRs)

**What this enables:**
- Automated email manifest parsing (extract attachments, parse order data)
- CSV/Excel upload interface with validation
- Manual order entry form for edge cases
- Raw + normalized data storage (keep original format + parsed data for debugging)
- Graceful degradation chain: API â†’ Email â†’ Manual entry

---

### Epic 3: Business Intelligence Dashboard

Business owners can track SLA performance, shortage costs, customer metrics, and operational efficiency through interactive dashboards with export capabilities to support data-driven decisions and contract negotiations.

**FRs covered:** FR1-FR7, FR11 (8 FRs)

**What this delivers:**
- Hero SLA section: Large percentage display (94.2%), trend indicator (+2.3%), color-coded progress bar
- Primary metrics cards: FADR (First Attempt Delivery Rate 92.1%), shortage claims (150K CLP), efficiency (42 min avg)
- Customer performance table: Sortable columns (Cliente, Pedidos, SLA %, FADR %, Fallos, Valor), color-coded SLA indicators (green â‰¥95%, yellow 90-95%, red <90%), export CSV
- Failed deliveries analysis: Chart.js bar chart (top 5 failure reasons with percentages), line chart (trend over time), peak/lowest insights
- Secondary metrics: Capacity utilization (89.2%), orders per hour (38.2), cost per delivery (2,847 CLP), satisfaction (4.6/5.0)
- Export reports: CSV/PDF generation for presentations and retailer meetings
- Historical data storage: Time-series data for trend analysis and contract negotiations

**Mockup:** âœ… business-owner-dashboard-desktop.html

---

### Epic 4: Pickup Verification Mobile PWA

Pickup crews can verify 300+ orders at retailer distribution centers using offline-capable mobile devices with real-time progress tracking, multi-sensory feedback, and digital audit trails to eliminate manual processes and prevent shortage penalties.

**FRs covered:** FR12-FR19 (8 FRs)

**What this delivers:**
- **Screen 1 - Manifest List:** Display today's pickups (Falabella 347 orders, Paris 189, Ripley 256), show customer name, order count, location, pickup time, status, tap card to select and start verification
- **Screen 2 - Scanning Workflow:** Real-time progress bar (0/347 â†’ 347/347), large scan area with animation, barcode/QR scanning via mobile camera, success feedback (green flash + beep sound + vibration), error feedback (red overlay + triple beep + vibration), offline indicator badge, scan validation against manifest
- **Screen 3 - Completion Summary:** Summary stats (orders verified, time elapsed, discrepancies count, precision percentage), digital signature capture (touch/mouse), generate PDF receipt button, return to manifest list
- Offline-first architecture: IndexedDB queue for scans, background sync when connectivity restored, optimistic UI updates
- Multi-sensory feedback: Audio (beep/triple-beep) + haptic (vibration) + visual (green/red overlay) for every scan
- PDF receipt generation: Complete audit trail (timestamp, user, order list, discrepancies, signature)
- Discrepancy reconciliation: Log mismatches for shortage claim prevention

**Mockup:** âœ… pickup-verification-mobile.html

**UX Pattern:** This same pattern (manifest list â†’ scanning â†’ completion) applies to Hub Reception and Loading workflows in post-MVP.

---

### Epic 5: Operations Control Center

Operations managers can monitor real-time capacity, order pipeline status, pickup progress, and receive automated alerts through responsive dashboards (desktop + mobile) to enable proactive resource planning and prevent capacity overruns.

**FRs covered:** FR38-FR41, FR64, FR67-FR70 (10 FRs)

**What this delivers:**

**Desktop Interface (1440px+):**
- Collapsible sidebar navigation: Hover to expand (70px â†’ 250px), click to lock, navigate sections (Ops Control, Business Dashboard, Inventory, Fleet, Team, Reports, Settings), current section highlighted in Tractis gold (#e6c15c)
- Pipeline overview: 8 stages with real-time order counts (Ingresado, Verificado, En Bodega, Asignado, En Carga, Listo, En Ruta, Entregado), compact cards visible without scrolling
- Orders table: Status indicators (ðŸ”´ urgent, ðŸŸ¡ alert, ðŸŸ¢ ok, âš« late), delivery promise dates with smart relative display ("Hoy", "MaÃ±ana"), time window countdowns with urgency levels, sortable/filterable columns, pagination
- Interactive features: Click pipeline cards to filter, search orders, live countdown simulation

**Mobile Interface (428px max-width):**
- Bottom tab bar navigation: 5 tabs (ðŸ“Š Ops, ðŸ’° Dashboard, ðŸ“¦ Orders, ðŸ“ˆ Reports, âš™ï¸ More), thumb-optimized positioning (60px from bottom), active tab highlighted in gold, badge indicator for urgent items, header updates based on active tab
- Card-based touch UI: Status summary cards (Urgent/Alert/OK), essential order info at a glance, large touch targets (44px minimum), pull-to-refresh gesture, swipe interactions

**Real-Time Features:**
- Order visibility from retailer e-commerce systems (live ingestion tracking)
- Automated capacity limit alerts (email/SMS when approaching agreed limits)
- Retailer forecast accuracy tracking (predicted vs actual volumes with variance %)
- 1-2 day resource planning forecasts (staffing, truck allocation based on incoming orders)
- Audit log access for troubleshooting (search by user, action, timestamp, resource)

**Platform Monitoring (Aureon DevOps):**
- Platform health dashboard (uptime, API response times, error rates, database performance)
- Customer usage analytics (active users per operator, API volume, feature adoption rates)
- SLA breach alerts (automated notifications when uptime/performance thresholds breached)
- Infrastructure scaling controls (manage database replicas, API servers, CDN)

**Mockups:** âœ… operations-control-center-desktop.html, operations-control-center-mobile.html


---

## Epic 1: Platform Foundation & Multi-Tenant SaaS Setup

Aureon DevOps can provision secure, isolated operator tenants with complete authentication, role-based access control, and audit infrastructure on a production-ready tech stack.

**FRs covered:** Starter Template (Architecture), FR50-FR58, FR65-FR66, FR71-FR72, FR79-FR82 (19 FRs)

---

### Story 1.1: Clone and Deploy Razikus Template Skeleton

As an Aureon DevOps engineer,
I want to clone the Razikus Supabase-Next.js template and deploy the base application to Vercel, Railway, and Supabase,
So that we have a working multi-tenant foundation with authentication already configured.

**Acceptance Criteria:**

**Given** I have access to the Razikus template repository (https://github.com/Razikus/supabase-nextjs-template)
**When** I clone the template and configure environment variables
**Then** The Next.js 14 frontend deploys successfully to Vercel with automatic HTTPS
**And** The application connects to a new Supabase project (PostgreSQL database + Auth + Storage)
**And** The base authentication flow works (sign up, login, logout)
**And** Environment variables are configured: NEXT_PUBLIC_SUPABASE_URL, NEXT_PUBLIC_SUPABASE_ANON_KEY, SUPABASE_SERVICE_KEY
**And** GitHub repository is created with main branch protected (requires PR for merges)
**And** I can access the deployed application at a custom Vercel URL

**Edge Cases:**
- Supabase project creation fails â†’ Retry with error logging
- Vercel deployment fails â†’ Check build logs and environment variables
- Template has breaking changes â†’ Pin to specific commit hash for stability

---

### Story 1.2: Configure Multi-Tenant Database Schema with RLS Policies

As an Aureon DevOps engineer,
I want to create the operators table with Row-Level Security policies enforced at the database level,
So that each operator's data is completely isolated and no operator can access another operator's data.

**Acceptance Criteria:**

**Given** Supabase PostgreSQL database is accessible
**When** I run the migration to create the operators table and RLS policies
**Then** The operators table exists with fields: id (UUID), name (VARCHAR), slug (VARCHAR unique), created_at (TIMESTAMP), deleted_at (TIMESTAMP nullable)
**And** RLS is enabled on the operators table
**And** A helper function auth.operator_id() returns the current user's operator_id from JWT claims
**And** RLS policy "tenant_isolation" is created: FOR ALL USING (id = auth.operator_id())
**And** Test queries confirm: User with operator_id 'A' cannot SELECT/INSERT/UPDATE/DELETE rows where operator_id = 'B'
**And** Migration is tracked in Supabase migrations folder with descriptive filename (e.g., 20260207_create_operators_table.sql)

**Edge Cases:**
- RLS not enabled â†’ Migration fails with clear error message
- Helper function auth.operator_id() returns NULL â†’ Queries return empty results (fail-secure)
- Migration rollback â†’ Drops table and policies cleanly

---

### Story 1.3: Implement Role-Based Authentication (5 Roles)

As an Aureon DevOps engineer,
I want to extend Supabase Auth with 5 distinct user roles (pickup_crew, warehouse_staff, loading_crew, operations_manager, admin),
So that users have permissions appropriate to their job function.

**Acceptance Criteria:**

**Given** Supabase Auth is configured from the Razikus template
**When** I create the users table with role and operator_id fields
**Then** The users table exists with fields: id (UUID, FK to auth.users), operator_id (UUID, FK to operators), role (ENUM), email (VARCHAR), full_name (VARCHAR), created_at (TIMESTAMP), deleted_at (TIMESTAMP nullable)
**And** The role ENUM includes exactly: 'pickup_crew', 'warehouse_staff', 'loading_crew', 'operations_manager', 'admin'
**And** RLS policy on users table enforces: Users can only see users from their own operator (operator_id = auth.operator_id())
**And** A database trigger automatically creates a users table entry when a new auth.users record is created (linking id to id)
**And** JWT tokens include custom claims: { operator_id: 'uuid', role: 'pickup_crew' }
**And** Frontend can access role via useUser() hook or equivalent

**Edge Cases:**
- User signup without operator_id â†’ Registration fails with error "Operator required"
- Invalid role value â†’ Database constraint violation error
- User tries to change their own role via API â†’ RLS policy blocks update (only admins can change roles)

---

### Story 1.4: Build User Management Interface (Create Users, Assign Roles)

As an admin user,
I want to create user accounts and assign them to roles and operators via a web interface,
So that I can onboard new users without writing SQL queries.

**Acceptance Criteria:**

**Given** I am logged in as a user with role 'admin'
**When** I navigate to /admin/users and click "Create User"
**Then** A form displays with fields: Email, Full Name, Role (dropdown: pickup_crew, warehouse_staff, loading_crew, operations_manager, admin), Operator (dropdown of operators I have access to)
**And** Submitting the form creates a new auth.users record and corresponding users table entry
**And** The new user receives a password setup email via Supabase Auth
**And** The users table displays all users for my operator in a sortable table (columns: Email, Full Name, Role, Created At, Actions)
**And** I can edit a user's role or full_name by clicking "Edit" (opens modal with form)
**And** I can soft-delete a user by clicking "Delete" (sets deleted_at = NOW(), user can no longer log in)
**And** Non-admin users cannot access /admin/users (route guard redirects to / with error toast)

**Edge Cases:**
- Email already exists â†’ Form validation error: "User with this email already exists"
- User creation fails (Supabase error) â†’ Display error toast with actionable message
- Editing user from different operator â†’ API returns 403 Forbidden (RLS policy blocks)
- Soft-deleted user tries to log in â†’ Supabase Auth blocks login with error "Account disabled"

---

### Story 1.5: Add PWA Enhancement Layer (Serwist + IndexedDB + Background Sync)

As a pickup crew member,
I want the mobile app to work offline and automatically sync my scans when connectivity is restored,
So that I can continue working in warehouses with unreliable WiFi.

**Acceptance Criteria:**

**Given** The Next.js app is deployed to Vercel
**When** I install and configure Serwist for service worker management
**Then** A service worker is registered on app load (visible in Chrome DevTools > Application > Service Workers)
**And** The app shell (HTML, CSS, JS bundles) is cached using cache-first strategy
**And** API requests use network-first strategy with 5-second timeout fallback to cache
**And** An offline fallback page displays when network is unavailable and no cached data exists
**And** IndexedDB database "aureon_offline" is created with table "scan_queue" (id, order_id, barcode, timestamp, synced BOOLEAN, operator_id)
**And** Background Sync API is registered to trigger sync event on connectivity change
**And** When online, queued scans batch-upload to /api/scans/sync endpoint (max 100 per request)
**And** Successful sync updates scan_queue records: synced = TRUE
**And** Connection status banner displays: Green "Online" | Yellow "Offline - XX scans queued" | Gray "Syncing..."

**Edge Cases:**
- Service worker fails to install â†’ Log error to console, app works without offline capability
- IndexedDB quota exceeded (>50MB) â†’ Clear old synced records, show warning toast
- Sync fails (API error) â†’ Retry with exponential backoff (3 attempts over 15 min), then show persistent error notification
- User clears browser cache â†’ IndexedDB persists, queued scans safe

**Technical Requirements:**
- Install Serwist: npm install @serwist/next
- Configure in next.config.js with caching strategies
- Use Dexie.js for type-safe IndexedDB operations

---

### Story 1.6: Set Up Audit Logging Infrastructure

As an admin user,
I want all data access and modifications logged with user, operator, timestamp, and action details,
So that I can investigate security incidents and comply with Chilean 7-year retention law.

**Acceptance Criteria:**

**Given** The database is configured with RLS policies
**When** I create the audit_logs table and database triggers
**Then** The audit_logs table exists with fields: id (UUID), operator_id (UUID), user_id (UUID), action (VARCHAR 50), resource_type (VARCHAR 50), resource_id (UUID nullable), changes_json (JSONB nullable), ip_address (VARCHAR 50), timestamp (TIMESTAMP default NOW())
**And** RLS policy enforces: Users can only query audit_logs for their own operator
**And** Database triggers automatically create audit log entries for: INSERT, UPDATE, DELETE on orders, manifests, inventory, users tables
**And** Audit log entries capture: user_id from JWT, operator_id from RLS context, action ('SCAN_ORDER', 'CREATE_USER', 'DELETE_MANIFEST'), changes_json (before/after state for UPDATEs)
**And** IP address is captured from request headers (X-Forwarded-For or X-Real-IP)
**And** Admins can view audit logs at /admin/audit-logs with filters: Date range, User, Action type, Resource type
**And** Audit logs are retained for 7 years (PostgreSQL retention policy configured)

**Edge Cases:**
- Trigger fails to create audit log â†’ Original operation succeeds, log error to Sentry
- changes_json exceeds JSONB size limit â†’ Truncate to first 10KB with indicator "...truncated"
- IP address header missing â†’ Store as "unknown"
- Querying >100K audit logs â†’ Pagination with 100 records per page

---

### Story 1.7: Configure CI/CD Pipeline (GitHub Actions)

As an Aureon DevOps engineer,
I want automated testing and deployment on every Git push,
So that code quality is enforced and deployments are consistent.

**Acceptance Criteria:**

**Given** The GitHub repository exists with main branch
**When** I create .github/workflows/ci.yml and .github/workflows/deploy.yml
**Then** The CI workflow runs on every push and PR with jobs: npm run test (Jest unit tests), npm run type-check (TypeScript compilation), npm run lint (ESLint), npm run build (verify Next.js builds successfully)
**And** All jobs must pass before PR can be merged to main (branch protection rule enforced)
**And** The deploy workflow runs on merge to main with jobs: Deploy frontend to Vercel production, Deploy backend to Railway production, Run Supabase migrations via CLI
**And** PR deployments create preview environments: Vercel preview URL, Railway preview environment, Supabase branch database
**And** GitHub Actions secrets are configured: VERCEL_TOKEN, RAILWAY_TOKEN, SUPABASE_ACCESS_TOKEN
**And** Build status badges display in README.md

**Edge Cases:**
- Tests fail on PR â†’ Deployment blocked, PR status shows red X
- Vercel deployment fails â†’ Rollback to previous version automatically, alert DevOps via email
- Migration fails on production â†’ Stop deployment, alert DevOps, require manual intervention
- Preview environment cleanup â†’ Delete after 7 days or when PR is closed

---

### Story 1.8: Set Up Monitoring and Alerting (Sentry + BetterStack)

As an Aureon DevOps engineer,
I want real-time error tracking and uptime monitoring with automated alerts,
So that I know immediately when the platform is down or throwing errors.

**Acceptance Criteria:**

**Given** The application is deployed to Vercel and Railway
**When** I configure Sentry and BetterStack integrations
**Then** Sentry is initialized in the Next.js app with DSN from environment variable SENTRY_DSN
**And** Frontend errors are captured with stack traces, user context (user_id, operator_id, role), and breadcrumbs (last 10 user actions)
**And** Backend API errors are captured with request context (endpoint, method, headers, body)
**And** Sentry groups errors by fingerprint and shows error count, affected users, first/last seen
**And** BetterStack monitors endpoints: https://app.aureon.com (every 5 minutes), https://api.aureon.com/health (every 5 minutes)
**And** Uptime alerts are sent via email and SMS when: Endpoint down >5 minutes, Response time >10 seconds, SSL certificate expires in <7 days
**And** Error alerts are sent via email when: Error rate >5% over 5-minute window, New error type appears, Error affects >10 users

**Edge Cases:**
- Sentry initialization fails â†’ App works normally, errors not tracked (fail-open)
- BetterStack API unreachable â†’ No uptime monitoring, alert DevOps manually
- Alert fatigue (too many alerts) â†’ Group similar alerts, send digest every 30 minutes instead of per-error
- Free tier limits exceeded (5,000 Sentry errors/month) â†’ Throttle error reporting to critical errors only


---

## Epic 2: Order Data Ingestion

Operations managers can import retailer orders into the platform via email manifests, CSV uploads, or manual entry with graceful fallback mechanisms.

**FRs covered:** FR8-FR10, FR47 (4 FRs)

---

### Story 2.1: Create Orders and Packages Tables with Data Model

As an Aureon DevOps engineer,
I want to create the orders and packages tables with fields for both normalized data and raw retailer format,
So that we can store orders from multiple sources, track individual scannable packages (cartons), and re-process if parsing errors occur.

**Note:** Scope expanded during implementation (2026-02-17) to include packages table (16 columns) based on domain analysis. Packages are the scannable units (CTN labels) that compose orders, supporting barcode scanning workflows in Epic 4 (Pickup Verification).

**Acceptance Criteria:**

**Given** The multi-tenant database is configured with RLS
**When** I run the migration to create the orders table
**Then** The orders table exists with fields: id (UUID), operator_id (UUID), order_number (VARCHAR 50 unique per operator), customer_name (VARCHAR 255), customer_phone (VARCHAR 20), delivery_address (TEXT), comuna (VARCHAR 100), delivery_date (DATE), delivery_window_start (TIME), delivery_window_end (TIME), retailer_name (VARCHAR 50), raw_data (JSONB), imported_via (ENUM: 'API', 'EMAIL', 'MANUAL', 'CSV'), imported_at (TIMESTAMP), created_at (TIMESTAMP), deleted_at (TIMESTAMP nullable)
**And** RLS policy enforces: Users can only access orders for their operator (operator_id = auth.operator_id())
**And** Unique constraint on (operator_id, order_number) prevents duplicate order numbers within an operator
**And** Index created on (operator_id, delivery_date) for fast date-range queries
**And** Index created on (operator_id, order_number) for fast order lookups
**And** raw_data JSONB field stores the original data format from retailer (email/CSV/API payload)

**Edge Cases:**
- Duplicate order_number within operator â†’ INSERT fails with constraint violation error
- raw_data exceeds 1MB â†’ Truncate with indicator in metadata
- Invalid delivery_date format â†’ Database rejects with type mismatch error

---

### Story 2.2: Build CSV/Excel Upload Interface with Validation

As an operations manager,
I want to upload a CSV or Excel file with orders and see validation results before importing,
So that I can quickly import manifests received via email or downloaded from retailer portals.

**Acceptance Criteria:**

**Given** I am logged in as an operations_manager or admin
**When** I navigate to /orders/import and select "Upload CSV/Excel"
**Then** A file upload dropzone displays with accepted formats: .csv, .xlsx, .xls (max 10MB file size)
**And** Dragging a file or clicking "Browse" opens file picker
**And** After file selection, the system parses the file and displays a preview table with first 10 rows
**And** Required columns are validated: order_number, customer_name, customer_phone, delivery_address, comuna, delivery_date (format: YYYY-MM-DD or DD/MM/YYYY)
**And** Missing required columns show error: "Missing required column: [column_name]"
**And** Optional columns are imported if present: delivery_window_start, delivery_window_end, retailer_name, notes
**And** Data validation errors display inline: Invalid phone format (not 9 digits), invalid date format, missing required field, duplicate order_number in file
**And** Valid rows show green checkmark, invalid rows show red X with error message
**And** Bottom summary shows: "X valid rows, Y errors" with button "Import X Valid Orders" (disabled if 0 valid)
**And** Clicking "Import" creates orders in database with imported_via = 'CSV', raw_data = entire row as JSON
**And** Success toast displays: "Imported X orders successfully. Y errors skipped."
**And** Failed rows can be exported as CSV with error column for correction and re-upload

**Edge Cases:**
- File exceeds 10MB â†’ Error: "File too large. Maximum 10MB."
- File is not CSV/Excel â†’ Error: "Invalid file format. Please upload .csv or .xlsx"
- CSV has wrong encoding (not UTF-8) â†’ Auto-detect and convert, or show encoding error
- Duplicate order_number already exists in database â†’ Mark as error: "Order #123 already exists"
- 0 valid rows â†’ Disable import button, show "Fix errors before importing"

---

### Story 2.3: Implement Email Manifest Parsing (n8n Workflow)

As an operations manager,
I want the system to automatically parse order manifests received via email attachments,
So that I don't have to manually download and upload CSVs for every retailer email.

**Acceptance Criteria:**

**Given** n8n is deployed on Railway and connected to Supabase
**When** An email arrives at manifests@aureon.com with CSV/Excel attachment
**Then** n8n workflow triggers on new email receipt
**And** Workflow extracts: Sender email, subject, body text, all attachments (CSV/Excel/PDF)
**And** For each CSV/Excel attachment: Parse file using same validation logic as Story 2.2, create orders in database with imported_via = 'EMAIL', raw_data = {email_subject, sender_email, attachment_name, parsed_row}
**And** Retailer name is auto-detected from sender email domain (falabella.cl â†’ "Falabella", shopee.cl â†’ "Shopee") or extracted from subject line
**And** Successfully parsed orders create audit log entries: action = 'EMAIL_IMPORT', resource_type = 'order'
**And** Parsing errors log to Sentry with context: email subject, sender, attachment name, error details
**And** Operations manager receives summary email: "Imported X orders from [retailer]. Y errors occurred." with link to /orders/import/results/[batch_id]
**And** /orders/import/results/[batch_id] page shows: Email subject, sender, timestamp, list of imported orders, list of errors with details

**Edge Cases:**
- Email has no attachments â†’ Log warning, send reply: "No manifest file found. Please attach CSV/Excel."
- Attachment is PDF (scanned manifest) â†’ Skip for now, log "PDF parsing not implemented", send reply: "PDF manifests not supported yet. Please send CSV/Excel."
- Attachment is corrupt/unreadable â†’ Log error to Sentry, send reply: "Could not read attachment. Please resend."
- Duplicate orders in email + database â†’ Skip duplicates, import new ones, summary shows: "Skipped X duplicates"
- Sender email not recognized â†’ Import with retailer_name = NULL, operations manager can edit later

**Technical Requirements:**
- n8n workflow nodes: Email Trigger (IMAP) â†’ Extract Attachments â†’ Parse CSV/Excel â†’ HTTP Request to API (POST /api/orders/bulk-import) â†’ Send Summary Email
- API endpoint /api/orders/bulk-import accepts: [{order_number, customer_name, ...}, ...], returns: {imported: count, errors: [{row, message}]}

---

### Story 2.4: Build Manual Order Entry Form (Fallback)

As an operations manager,
I want to manually enter a single order via a web form,
So that I can add orders when email and CSV fail or for one-off special deliveries.

**Acceptance Criteria:**

**Given** I am logged in as an operations_manager or admin
**When** I navigate to /orders/new and fill out the manual entry form
**Then** A form displays with fields: Order Number (required, text), Customer Name (required, text), Customer Phone (required, text with validation: 9 digits), Delivery Address (required, textarea), Comuna (required, autocomplete dropdown from Chilean comuna list), Delivery Date (required, date picker), Delivery Window Start (optional, time picker), Delivery Window End (optional, time picker), Retailer Name (optional, dropdown: Falabella, Shopee, Mercado Libre, Ripley, Paris, Other), Notes (optional, textarea)
**And** Real-time validation on blur: Phone must be 9 digits (format: +56912345678 or 912345678), Order number cannot be duplicate (AJAX check), Comuna must be valid Chilean comuna
**And** Clicking "Save Order" creates order in database with imported_via = 'MANUAL', raw_data = {form_values, created_by: user_id}
**And** Success toast displays: "Order #[order_number] created successfully" with link to order detail page
**And** Form resets for next order entry with button "Add Another Order"
**And** Validation errors display inline in red below each field
**And** Submit button disabled until all required fields valid

**Edge Cases:**
- Duplicate order_number â†’ Form error: "Order #123 already exists for this operator"
- Invalid phone format â†’ Form error: "Phone must be 9 digits"
- Future delivery date >30 days away â†’ Warning (not error): "Delivery date is more than 30 days away. Confirm?"
- Missing required field on submit â†’ Focus first invalid field, show error message


---

## Epic 3: Business Intelligence Dashboard

Business owners can track SLA performance, shortage costs, customer metrics, and operational efficiency through interactive dashboards with export capabilities to support data-driven decisions and contract negotiations.

**FRs covered:** FR1-FR7, FR11 (8 FRs)

**Mockup:** âœ… business-owner-dashboard-desktop.html

---

### Story 3.1: Create Performance Metrics Tables and Calculation Logic

As an Aureon DevOps engineer,
I want to create database tables and functions for calculating SLA, FADR, and other performance metrics,
So that dashboard queries are fast and metrics are consistently calculated.

**Acceptance Criteria:**

**Given** The orders table exists with delivery data
**When** I create the performance_metrics and delivery_attempts tables with calculation functions
**Then** The delivery_attempts table exists with fields: id (UUID), operator_id (UUID), order_id (UUID FK), attempt_number (INT), status (ENUM: 'success', 'failed', 'returned'), failure_reason (VARCHAR 100 nullable), attempted_at (TIMESTAMP), driver_id (UUID nullable), created_at (TIMESTAMP)
**And** The performance_metrics table exists with fields: id (UUID), operator_id (UUID), metric_date (DATE), retailer_name (VARCHAR 50 nullable for per-retailer metrics), total_orders (INT), delivered_orders (INT), first_attempt_deliveries (INT), failed_deliveries (INT), shortage_claims_count (INT), shortage_claims_amount_clp (DECIMAL), avg_delivery_time_minutes (DECIMAL), created_at (TIMESTAMP), updated_at (TIMESTAMP)
**And** Unique constraint on (operator_id, metric_date, retailer_name) prevents duplicate metrics
**And** Database function calculate_sla(operator_id, start_date, end_date) returns: (delivered_orders / total_orders * 100) as percentage
**And** Database function calculate_fadr(operator_id, start_date, end_date) returns: (first_attempt_deliveries / total_orders * 100) as percentage
**And** Database function get_failure_reasons(operator_id, start_date, end_date) returns: JSON array of {reason, count, percentage}
**And** Nightly cron job (PostgreSQL pg_cron or Railway cron) runs at 2 AM to calculate yesterday's metrics for all operators and insert into performance_metrics table

**Edge Cases:**
- Division by zero (no orders on a day) â†’ Return NULL or 0% with indicator
- Missing delivery attempt data â†’ SLA calculation excludes orders without attempts
- Metrics calculation fails â†’ Log to Sentry, send alert, retry next night

---

### Story 3.2: Build Hero SLA Section with Real-Time Calculation

As a business owner,
I want to see a prominent SLA percentage with trend indicator at the top of my dashboard,
So that I immediately know if delivery performance is improving or declining.

**Acceptance Criteria:**

**Given** I am logged in as admin or operations_manager and navigate to /dashboard
**When** The dashboard loads
**Then** The hero SLA section displays prominently at top with: Large percentage display (e.g., "94.2%"), Size: 48px font, Tractis gold (#e6c15c) if â‰¥95%, yellow if 90-95%, red if <90%
**And** Trend indicator shows: Arrow icon (â†‘ green if improving, â†“ red if declining), Percentage change from previous 7-day period (e.g., "+2.3%"), Comparison text: "vs. previous 7 days"
**And** Progress bar visualization below percentage: Width 100%, filled portion = SLA percentage, color matches percentage color coding
**And** Hover tooltip displays: "SLA: [delivered_orders] delivered / [total_orders] total orders", Date range: "Last 7 days ([start_date] - [end_date])"
**And** Clicking SLA section opens drill-down modal showing: Daily SLA breakdown (7-day chart), Per-retailer SLA table, Failed orders list with reasons
**And** Data refreshes every 30 seconds using TanStack Query background refetch
**And** Loading state shows skeleton loader (pulsing gray rectangle) while data fetches

**Edge Cases:**
- No orders in last 7 days â†’ Display "N/A" with message "No orders in this period"
- SLA calculation in progress â†’ Show loading spinner
- API error â†’ Display last cached value with warning icon "Data may be outdated"

---

### Story 3.3: Implement Primary Metrics Cards (FADR, Claims, Efficiency)

As a business owner,
I want to see key operational metrics (FADR, shortage claims, delivery efficiency) in prominent cards below the SLA section,
So that I can quickly assess overall performance.

**Acceptance Criteria:**

**Given** I am viewing the dashboard at /dashboard
**When** The page loads below the hero SLA section
**Then** Three primary metrics cards display side-by-side: FADR card, Shortage Claims card, Efficiency card
**And** Each card shows: Large metric value (32px font), Metric label (16px, gray), Trend indicator (â†‘/â†“ with percentage change vs. previous period), Small line chart (Chart.js) showing last 7 days trend
**And** FADR Card displays: Percentage (e.g., "92.1%"), Label: "First Attempt Delivery Rate", Color: Green if â‰¥90%, yellow if 80-90%, red if <80%, Calculation: (first_attempt_deliveries / total_orders * 100)
**And** Shortage Claims Card displays: Amount in CLP (e.g., "150,000 CLP"), Label: "Shortage Claims (Last 30 Days)", Color: Red if >100K, yellow if 50K-100K, green if <50K, Breakdown on hover: Count of claims, Average per claim
**And** Efficiency Card displays: Time in minutes (e.g., "42 min"), Label: "Avg. Delivery Time", Color: Green if â‰¤40min, yellow if 40-60min, red if >60min, Calculation: Average time from pickup to delivery
**And** Clicking any card opens detailed view with: Full historical chart (30-day), Breakdown by retailer, Contributing factors

**Edge Cases:**
- No delivery attempts â†’ FADR shows "N/A"
- No shortage claims â†’ Shows "0 CLP" in green
- Metric calculation fails â†’ Show last cached value with staleness indicator

---

### Story 3.4: Build Customer Performance Table (Sortable, Color-Coded)

As a business owner,
I want to see a table of all retailers with their performance metrics in sortable columns,
So that I can identify which customers are performing well and which need attention.

**Acceptance Criteria:**

**Given** I am viewing the dashboard below the primary metrics cards
**When** The customer performance table loads
**Then** A table displays with columns: Cliente (retailer name), Pedidos (order count), SLA % (on-time delivery), FADR % (first attempt rate), Fallos (failed delivery count), Valor (revenue or order value), Actions (view details button)
**And** Default sort: By Pedidos (order count) descending (largest customers first)
**And** Clicking any column header toggles sort ascending/descending with visual indicator (â†‘/â†“ icon)
**And** SLA % column has color-coded background: Green if â‰¥95%, Yellow if 90-95%, Red if <90%
**And** FADR % column has color-coded background: Green if â‰¥90%, Yellow if 80-90%, Red if <80%
**And** Each row shows data for last 30 days by default
**And** Date range filter above table: Dropdown (Last 7 days, Last 30 days, Last 90 days, Custom range)
**And** Search box filters table by retailer name (client-side filter, instant)
**And** Pagination: 10 rows per page with "Load More" button at bottom
**And** "Export CSV" button top-right downloads table data with current filters/sort applied

**Edge Cases:**
- No data for retailer in period â†’ Show "0" for metrics, gray background
- Retailer name too long â†’ Truncate with ellipsis, full name on hover
- Table >100 retailers â†’ Virtual scrolling or pagination for performance

---

### Story 3.5: Create Failed Deliveries Analysis with Chart.js Visualizations

As a business owner,
I want to see visual charts analyzing failed delivery reasons and trends,
So that I can identify patterns and address root causes.

**Acceptance Criteria:**

**Given** I am viewing the dashboard below the customer table
**When** The failed deliveries analysis section loads
**Then** Two charts display side-by-side: Bar chart (failure reasons), Line chart (trend over time)
**And** Bar Chart shows: Title: "Top 5 Failure Reasons (Last 30 Days)", X-axis: Failure reasons (e.g., "Cliente ausente", "DirecciÃ³n incorrecta", "Rechazado"), Y-axis: Count of occurrences, Bars colored by severity: Red (>50 occurrences), Yellow (20-50), Gray (<20), Percentage label on each bar (e.g., "Cliente ausente: 34%")
**And** Line Chart shows: Title: "Failed Deliveries Trend (Last 30 Days)", X-axis: Dates, Y-axis: Failed delivery count, Single line showing daily failed deliveries, Red color (#ef4444), Hover tooltip shows: Date, count, top failure reason for that day, Peak/Lowest annotations: "Peak: [date] ([count] failures)", "Lowest: [date] ([count] failures)"
**And** Both charts use Chart.js library with responsive sizing (resize with window)
**And** Clicking bar or line point opens drill-down: Filtered order list for that reason/date, Ability to export filtered list
**And** Date range filter applies to both charts simultaneously

**Edge Cases:**
- No failed deliveries in period â†’ Show empty state: "Great news! No failed deliveries in this period."
- <5 failure reasons â†’ Show all reasons, not just top 5
- Chart rendering fails â†’ Show error message with retry button

---

### Story 3.6: Add Secondary Metrics Dashboard

As a business owner,
I want to see additional operational metrics (capacity utilization, orders/hour, cost/delivery, customer satisfaction),
So that I have a complete picture of business performance.

**Acceptance Criteria:**

**Given** I am viewing the dashboard below the failed deliveries charts
**When** The secondary metrics section loads
**Then** Four smaller metric cards display in a row: Capacity Utilization, Orders per Hour, Cost per Delivery, Customer Satisfaction
**And** Capacity Utilization card shows: Percentage (e.g., "89.2%"), Label: "Capacity Utilization", Color: Yellow if >85%, green if 60-85%, red if <60% or >95%, Calculation: (actual_orders / forecasted_capacity * 100), Tooltip: "Actual: X orders, Capacity: Y orders"
**And** Orders per Hour card shows: Number (e.g., "38.2"), Label: "Orders Processed per Hour", Color: Green if â‰¥40, yellow if 30-40, red if <30, Calculation: Total orders processed / total operational hours
**And** Cost per Delivery card shows: Amount in CLP (e.g., "2,847 CLP"), Label: "Average Cost per Delivery", Color: Green if â‰¤2500, yellow if 2500-3500, red if >3500, Breakdown on hover: Labor cost, fuel cost, overhead
**And** Customer Satisfaction card shows: Rating out of 5 (e.g., "4.6/5.0"), Label: "Customer Satisfaction", Star rating visualization (filled stars), Color: Green if â‰¥4.5, yellow if 4.0-4.5, red if <4.0
**And** All cards show trend indicators (â†‘/â†“ percentage change vs. previous period)

**Edge Cases:**
- Missing satisfaction data â†’ Show "N/A" with message "No satisfaction surveys completed"
- Cost data incomplete â†’ Show estimate with disclaimer icon
- Capacity forecast not set â†’ Show "Capacity not configured" with link to settings

---

### Story 3.7: Implement Export Functionality (CSV/PDF Reports)

As a business owner,
I want to export dashboard data as CSV or PDF reports,
So that I can share performance data with stakeholders and use in presentations.

**Acceptance Criteria:**

**Given** I am viewing the complete dashboard with all metrics loaded
**When** I click the "Export Report" button in the actions bar
**Then** A modal opens with export options: Format (CSV or PDF radio buttons), Date Range (Last 7/30/90 days or Custom), Include Sections (checkboxes: SLA Summary, Metrics, Customer Table, Failed Deliveries Chart, Secondary Metrics), File Name (editable text field, default: "aureon-dashboard-[date].csv")
**And** Clicking "Export CSV" downloads a CSV file containing: All selected sections as separate sheets (if multi-sheet format supported) or clearly labeled sections, Customer table with all columns and current filters, Metrics as rows: Metric Name, Value, Change vs. Previous Period, Date Range
**And** Clicking "Export PDF" generates a formatted PDF report with: Company logo (configurable in settings), Report title: "Aureon Performance Dashboard", Date range and generation timestamp, All selected sections with charts rendered as images, Page numbers and table of contents, Footer: "Generated by Aureon Last Mile"
**And** PDF uses professional styling: Tractis color scheme, Clean table formatting, Chart.js charts exported as high-res PNG, Page breaks between major sections
**And** Export progress shows: "Generating report..." with spinner, Success toast: "Report downloaded: [filename]", Download starts automatically
**And** Generated reports are logged in audit_logs: action = 'EXPORT_DASHBOARD', resource_type = 'report', metadata includes date range and sections

**Edge Cases:**
- Export >1000 rows in customer table â†’ Paginate or warn about large file size
- PDF generation fails â†’ Fallback to CSV export with error message
- Chart rendering in PDF fails â†’ Include data table instead of chart
- User cancels during generation â†’ Abort export, clean up temp files

---

### Story 3.8: Set Up TanStack Query Caching for Dashboard Performance

As a business owner,
I want the dashboard to load quickly and not spam the API with redundant requests,
So that I have a smooth user experience even when switching between tabs.

**Acceptance Criteria:**

**Given** The dashboard uses TanStack Query for data fetching
**When** I navigate to /dashboard
**Then** TanStack Query is configured with: Stale time: 30 seconds (data considered fresh for 30s, no refetch), Cache time: 5 minutes (data kept in memory for 5min after last use), Background refetch: Every 60 seconds while page is active, Refetch on window focus: true (refresh when switching back to tab), Retry logic: 3 attempts with exponential backoff (1s, 2s, 4s delays)
**And** Query keys are structured hierarchically: ['dashboard', operator_id, 'sla', {start_date, end_date}], ['dashboard', operator_id, 'metrics', {period}], ['dashboard', operator_id, 'customers', {sort, filters}]
**And** Loading states show skeleton loaders (not spinners) for better perceived performance
**And** Error states show toast notification with retry button, last cached data remains visible with staleness indicator
**And** Optimistic updates: Date range changes show immediately with old data, then update when new data arrives
**And** Query invalidation: Creating/updating orders invalidates dashboard queries, Export action does NOT invalidate (read-only)
**And** DevTools integration: TanStack Query DevTools available in development mode (bottom-right corner icon)

**Edge Cases:**
- Network offline â†’ Show last cached data with "Offline" banner, queue refetch for when online
- API consistently failing â†’ Show error state after 3 retries, option to force refresh
- Multiple tabs open â†’ Shared cache across tabs (BroadcastChannel API), changes in one tab update others
- Cache size grows large (>50MB) â†’ Automatically prune oldest unused queries


---

## Epic 4: Pickup Verification Mobile PWA

Pickup crews can verify 300+ orders at retailer distribution centers using offline-capable mobile devices with real-time progress tracking, multi-sensory feedback, and digital audit trails to eliminate manual processes and prevent shortage penalties.

**FRs covered:** FR12-FR19 (8 FRs)

**Mockup:** âœ… pickup-verification-mobile.html

---

### Story 4.1: Create Manifests and Pickup Scans Tables

As an Aureon DevOps engineer,
I want to create database tables for manifests and pickup scans with proper relationships,
So that we can track which orders are assigned to which pickups and verify scan completeness.

**Acceptance Criteria:**

**Given** The orders table exists from Epic 2
**When** I create the manifests and pickup_scans tables
**Then** The manifests table exists with fields: id (UUID), operator_id (UUID), retailer_name (VARCHAR 50), pickup_location (TEXT), pickup_date (DATE), pickup_time_start (TIME), pickup_time_end (TIME), total_orders (INT), assigned_to_user_id (UUID FK to users, nullable), status (ENUM: 'pending', 'in_progress', 'completed', 'cancelled'), created_at (TIMESTAMP), completed_at (TIMESTAMP nullable)
**And** The manifest_orders junction table exists with fields: id (UUID), manifest_id (UUID FK), order_id (UUID FK), sequence_number (INT), created_at (TIMESTAMP)
**And** Unique constraint on (manifest_id, order_id) prevents duplicate orders in a manifest
**And** The pickup_scans table exists with fields: id (UUID), operator_id (UUID), manifest_id (UUID FK), order_id (UUID FK), barcode_scanned (VARCHAR 100), scan_status (ENUM: 'success', 'mismatch', 'duplicate'), scanned_by_user_id (UUID FK to users), scanned_at (TIMESTAMP), synced_to_server (BOOLEAN default false), created_at (TIMESTAMP)
**And** RLS policies enforce: Users can only access manifests/scans for their operator
**And** Index on (manifest_id, synced_to_server) for fast offline sync queries
**And** Index on (order_id) for fast scan validation lookups

**Edge Cases:**
- Order deleted but still in manifest â†’ Soft delete preserved, manifest shows as "Order not found"
- Manifest without orders â†’ total_orders = 0, can still complete with note
- Scan without matching order â†’ scan_status = 'mismatch', logged for review

---

### Story 4.2: Build Screen 1 - Manifest List (Today's Pickups)

As a pickup crew member,
I want to see all my assigned pickup manifests for today with order counts and locations,
So that I know which retailer DCs to visit and how many orders to verify.

**Acceptance Criteria:**

**Given** I am logged in as pickup_crew on a mobile device
**When** I navigate to /pickup (mobile PWA home screen)
**Then** Screen 1 displays with header: "Pickups - [Today's Date]", subtitle: "Tap a manifest to start verification"
**And** A list of manifest cards displays, each showing: Retailer name (large, bold, e.g., "Falabella"), Order count (e.g., "347 orders"), Location (e.g., "Centro de DistribuciÃ³n San Bernardo"), Pickup time window (e.g., "10:00 - 12:00"), Status badge (color-coded: Gray "Pending", Yellow "In Progress X/Y", Green "Completed âœ“")
**And** Default sort: By pickup_time_start ascending (earliest pickups first)
**And** Cards for manifests with status 'in_progress' show progress: "In Progress: 287/347 scanned"
**And** Tapping a manifest card navigates to Screen 2 (Scanning) with manifest_id in route: /pickup/scan/[manifest_id]
**And** If manifest status is 'pending', tapping updates status to 'in_progress' and sets assigned_to_user_id = current user
**And** If manifest status is 'completed', tapping shows completion summary (Screen 3) in read-only mode
**And** Pull-to-refresh gesture fetches latest manifest list from server (or queue for sync if offline)
**And** Empty state displays when no manifests: "No pickups assigned for today" with illustration

**Edge Cases:**
- No manifests for today â†’ Show empty state
- Manifest already assigned to different user â†’ Show warning: "Assigned to [user_name]. Contact supervisor to reassign."
- Offline on first load â†’ Show cached manifests from last sync with "Offline" banner
- Multiple pickups at same location â†’ Group by location with expandable section

---

### Story 4.3: Build Screen 2 - Barcode Scanning with Camera Integration

As a pickup crew member,
I want to scan package barcodes using my mobile camera and see instant validation feedback,
So that I can quickly verify all orders in the manifest.

**Acceptance Criteria:**

**Given** I tapped a manifest card and navigated to /pickup/scan/[manifest_id]
**When** Screen 2 loads
**Then** The screen displays: Header with back button and manifest info: "[Retailer] - [Order Count] orders", Large progress bar showing: "0 / 347" initially, updates in real-time, colored: Red if <50%, Yellow if 50-90%, Green if â‰¥90%, Large scan area (60% of screen height) with: Animated scanning line pulsing up/down, Camera viewfinder overlay (rounded rectangle target zone), Text: "Position barcode in frame" or "Tap to scan", Bottom stats bar: "âœ“ Verified: 0 | âœ— Errors: 0 | â± Time: 00:00"
**And** Camera permission is requested on first load with clear explanation: "We need camera access to scan barcodes"
**And** Camera auto-activates when screen loads (no "Start Camera" button needed)
**And** When barcode enters target zone: Auto-detect and scan using QuaggaJS or html5-qrcode library, Vibrate (100ms), Play beep sound, Immediately validate against manifest orders
**And** Manual scan button displays for devices without auto-scan or when camera fails: "Enter Barcode Manually" opens text input modal
**And** Scanned barcode is validated: If matches order in manifest â†’ Success flow (Story 4.4), If NOT in manifest â†’ Error flow (Story 4.4), If already scanned (duplicate) â†’ Duplicate warning
**And** Timer starts when first scan occurs, displays as "MM:SS" format

**Edge Cases:**
- Camera permission denied â†’ Show manual entry option with warning
- Poor lighting conditions â†’ Show message: "Move to better lighting" and increase camera exposure
- Barcode unreadable (damaged) â†’ After 3 failed scans, prompt manual entry
- QR code instead of barcode â†’ Support both formats
- Device doesn't support camera (desktop browser) â†’ Show keyboard input as primary method

---

### Story 4.4: Implement Multi-Sensory Feedback (Audio + Haptic + Visual)

As a pickup crew member,
I want to receive immediate multi-sensory confirmation when I scan a package,
So that I know the scan was registered even in noisy warehouse environments.

**Acceptance Criteria:**

**Given** I am on Screen 2 (Scanning) and scan a barcode
**When** The barcode validation completes
**Then** For SUCCESS (barcode matches manifest order): Visual feedback: Green flash overlay (500ms fade), success checkmark icon animation, progress bar increments (+1), "Verified" count increments, Audio feedback: Single beep sound (300ms, 800Hz tone), Haptic feedback: Single vibration pulse (100ms), UI update: Scanned order briefly highlights in green at bottom (3-second toast: "Order #12345 âœ“")
**And** For ERROR (barcode not in manifest): Visual feedback: Red overlay (1 second), X icon animation, shake animation on scan area, Audio feedback: Triple beep (200ms beeps with 100ms gaps, 400Hz lower tone), Haptic feedback: Three vibration pulses (100ms each with 100ms gaps), UI update: Error toast (5 seconds): "Order #[barcode] not in manifest. Contact supervisor.", "Errors" count increments
**And** For DUPLICATE (already scanned): Visual feedback: Yellow overlay (500ms), warning icon, Audio feedback: Double beep (200ms beeps, 600Hz tone), Haptic feedback: Double vibration pulse (100ms each), UI update: Warning toast (3 seconds): "Order #12345 already scanned at [time]"
**And** All feedback happens simultaneously (not sequentially) for instant perception
**And** Sound can be muted via settings toggle (visual + haptic remain)
**And** Haptic feedback respects device settings (disabled if device has haptics off)

**Technical Requirements:**
- Audio: Use Web Audio API or HTML5 Audio with preloaded sound files
- Haptic: Use Vibration API (navigator.vibrate)
- Visual: CSS animations with Tailwind or Framer Motion

**Edge Cases:**
- Device doesn't support vibration â†’ Visual + audio only
- Sound playback fails (iOS restrictions) â†’ Visual + haptic only, show toast: "Enable sound in settings"
- Multiple rapid scans â†’ Queue feedback, don't overlap (max 1 feedback per 200ms)

---

### Story 4.5: Build Offline Scan Queue with IndexedDB Storage

As a pickup crew member,
I want my scans to be saved locally when I'm offline,
So that I can continue working without WiFi and won't lose data.

**Acceptance Criteria:**

**Given** The PWA has IndexedDB configured from Epic 1 Story 1.5
**When** I scan a barcode on Screen 2
**Then** The scan is immediately saved to IndexedDB table "scan_queue" with fields: {id, manifest_id, order_id, barcode_scanned, scan_status, scanned_at, synced: false, operator_id, user_id}
**And** Optimistic UI update: Progress bar, counts, and feedback all update immediately (don't wait for server)
**And** Connection status banner displays at top: Green "Online - Syncing" when connected, Yellow "Offline - 15 scans queued" when disconnected, Gray "Syncing..." during background sync
**And** If online: Immediately POST scan to /api/pickup/scans endpoint, On success: Update IndexedDB record synced = true, On failure: Keep in queue, retry via background sync
**And** If offline: Save to IndexedDB only, Queue count displays in banner, No error shown to user (silent queueing)
**And** All scans remain in IndexedDB until synced (even if app is closed/refreshed)
**And** Progress bar and counts calculate from IndexedDB (local source of truth), not server

**Edge Cases:**
- IndexedDB quota exceeded (>50MB) â†’ Delete synced scans older than 7 days, show warning
- Scan saved locally but POST fails (server error) â†’ Keep in queue, show banner: "Will retry sync"
- App crashes mid-scan â†’ On restart, IndexedDB preserves all scans, resume where left off
- User switches manifests â†’ Current manifest scans saved, load different manifest from IndexedDB

---

### Story 4.6: Implement Background Sync When Connectivity Restored

As a pickup crew member,
I want my queued scans to automatically upload when WiFi returns,
So that I don't have to manually sync or worry about lost data.

**Acceptance Criteria:**

**Given** I have scans in IndexedDB with synced = false (offline queue)
**When** Network connectivity is restored (offline â†’ online transition)
**Then** Background Sync API registers sync event: "pickup-scans-sync"
**And** Sync handler triggers automatically (no user action needed)
**And** Sync process: Query IndexedDB for scans where synced = false, Batch scans by manifest_id (max 100 scans per request), POST to /api/pickup/scans/bulk endpoint: {manifest_id, scans: [{order_id, barcode, scanned_at, user_id}, ...]}, On success: Update IndexedDB records synced = true for uploaded scans, On failure: Retry with exponential backoff (1s, 2s, 4s delays, max 3 attempts)
**And** UI updates during sync: Banner changes to "Syncing... X scans remaining", Progress indicator (spinner), Toast on completion: "Synced 15 scans successfully"
**And** If sync partially fails (some scans succeed, some fail): Successful scans marked synced = true, Failed scans remain in queue, Show toast: "Synced 10/15 scans. 5 failed, will retry."
**And** Sync runs in background (Service Worker), works even if app tab is closed

**Technical Requirements:**
- Use Background Sync API: navigator.serviceWorker.ready.then(reg => reg.sync.register('pickup-scans-sync'))
- Service Worker listens for 'sync' event and handles upload
- Fallback for browsers without Background Sync: Use online event listener + manual fetch

**Edge Cases:**
- Network flaky (goes offline during sync) â†’ Pause sync, resume when stable
- Sync fails 3 times â†’ Show persistent error notification: "Sync failed. Check connection or contact support."
- User forces sync via button â†’ Trigger sync event manually, show progress
- Large queue (500+ scans) â†’ Batch in chunks of 100, show progress: "Syncing batch 1/5"

---

### Story 4.7: Build Screen 3 - Completion Summary with Digital Signature

As a pickup crew member,
I want to review the verification summary and capture a digital signature to confirm pickup completion,
So that we have legal proof of what was verified.

**Acceptance Criteria:**

**Given** I have scanned all orders (progress = 100%) or clicked "Complete Pickup" button
**When** Screen 3 loads at /pickup/complete/[manifest_id]
**Then** The screen displays completion summary: Header: "Pickup Complete - [Retailer]", Four stat cards in grid: "Orders Verified: 347" (large, green), "Time Elapsed: 1h 23m" (calculated from first to last scan), "Discrepancies: 2" (red if >0, green if 0, count of error scans), "Precision: 99.4%" (calculated: verified / total * 100)
**And** Discrepancies section (if errors > 0): List of unverified/error orders: "Order #12345 - Not found in manifest", "Order #67890 - Already scanned", Explanation text: "Contact supervisor about discrepancies before leaving"
**And** Digital signature capture area: Canvas element (300x150px), responsive to touch and mouse, Text: "Sign to confirm pickup", Clear button to reset signature, Signature required before completing (button disabled if empty)
**And** Two action buttons: "Generate Receipt" (primary, green), "Back to Scanning" (secondary, gray)
**And** Clicking "Generate Receipt" validates: Signature is not empty â†’ Error if empty: "Signature required", All critical errors resolved (configurable: allow minor discrepancies)
**And** On validation success: Save signature as base64 PNG to database (manifests.signature_data), Update manifest status = 'completed', completed_at = NOW(), Navigate to PDF receipt screen (Story 4.8)

**Edge Cases:**
- User tries to complete with 0 scans â†’ Block with error: "No orders scanned. Cannot complete."
- Signature too simple (single dot) â†’ Accept but log warning (no rejection, user might have simple signature)
- User navigates away without completing â†’ Scans saved in IndexedDB, can resume later
- Multiple discrepancies (>10) â†’ Require supervisor override code to complete

---

### Story 4.8: Generate PDF Receipt with Complete Audit Trail

As a pickup crew member,
I want to generate a PDF receipt showing all verified orders and my signature,
So that the retailer has proof of pickup and I have protection against future shortage claims.

**Acceptance Criteria:**

**Given** I completed the pickup and provided a digital signature
**When** I click "Generate Receipt" on Screen 3
**Then** A PDF is generated using jsPDF library with: Header section: "AUREON LAST MILE - PICKUP RECEIPT" title, Company logo (configurable), Receipt ID: [manifest_id] and date/time, Pickup details section: Retailer: [name], Location: [address], Date: [pickup_date], Time window: [start] - [end], Assigned to: [user full_name]
**And** Verification summary: Total orders in manifest: [count], Orders verified: [count] (green), Discrepancies: [count] (red if >0), Precision: [percentage], Time elapsed: [duration]
**And** Order list table (if â‰¤50 orders): Columns: Order Number, Status (âœ“ Verified or âœ— Error), Scanned At, All verified orders listed, Discrepancies highlighted in red with reason
**And** If >50 orders: Summary only, full list available via "Download Detailed List" button
**And** Discrepancy details section (if errors > 0): List of unverified orders with reasons, Retailer acknowledgment text: "Retailer acknowledges missing orders listed above"
**And** Signature section: Digital signature image (captured from Screen 3), Signature line with printed name: "[user full_name]", Date and time of signature
**And** Footer: "This is a legally binding document. Retain for 7 years per Chilean commercial law.", Page number (if multi-page), Generated by Aureon Last Mile
**And** PDF download options: Save to device (downloads/[manifest_id]-receipt.pdf), Email to supervisor (button: "Email Receipt"), Share via native share API (mobile)
**And** PDF generation logged in audit_logs: action = 'GENERATE_PICKUP_RECEIPT', resource_type = 'manifest', resource_id = manifest_id

**Technical Requirements:**
- Use jsPDF library for PDF generation
- Embed signature as base64 PNG image
- Support Spanish text (UTF-8 encoding)
- Professional formatting with Tractis branding

**Edge Cases:**
- PDF generation fails (memory limit) â†’ Fallback to simplified version (summary only, no order list)
- Email fails â†’ Show error toast, save PDF locally as backup
- Large manifest (500+ orders) â†’ Generate PDF in background, show progress, notify when ready
- Signature image too large â†’ Compress to max 100KB before embedding


---

## Epic 5: Operations Control Center

Operations managers can monitor real-time capacity, order pipeline status, pickup progress, and receive automated alerts through responsive dashboards (desktop + mobile) to enable proactive resource planning and prevent capacity overruns.

**FRs covered:** FR38-FR41, FR64, FR67-FR70 (10 FRs)

**Mockups:** âœ… operations-control-center-desktop.html, operations-control-center-mobile.html

---

### Story 5.1: Create Order Status Tracking and Capacity Forecast Tables

As an Aureon DevOps engineer,
I want to create tables for tracking order pipeline status and capacity forecasts,
So that operations managers can see real-time order flow and plan resources.

**Acceptance Criteria:**

**Given** The orders table exists with basic fields
**When** I extend the schema with status tracking and create forecast tables
**Then** The orders table is extended with fields: pipeline_status (ENUM: 'ingresado', 'verificado', 'en_bodega', 'asignado', 'en_carga', 'listo', 'en_ruta', 'entregado'), status_updated_at (TIMESTAMP), priority (ENUM: 'urgent', 'alert', 'ok', 'late'), delivery_promise_date (DATE), time_window_countdown_minutes (INT calculated field)
**And** The capacity_forecasts table exists with fields: id (UUID), operator_id (UUID), retailer_name (VARCHAR 50), forecast_date (DATE), forecasted_orders (INT), actual_orders (INT), variance_percentage (DECIMAL), created_at (TIMESTAMP), updated_at (TIMESTAMP)
**And** Unique constraint on (operator_id, retailer_name, forecast_date)
**And** Database function calculate_pipeline_counts(operator_id) returns JSON: {ingresado: count, verificado: count, en_bodega: count, ...}
**And** Database trigger auto-updates status_updated_at when pipeline_status changes
**And** Database function calculate_priority(delivery_date, current_time) returns: 'urgent' if <45min to deadline, 'alert' if 45min-2hr, 'ok' if >2hr, 'late' if past deadline
**And** Index on (operator_id, pipeline_status) for fast status filtering
**And** Index on (operator_id, delivery_promise_date) for deadline queries

**Edge Cases:**
- Order moves backward in pipeline (e.g., en_ruta â†’ en_bodega for returns) â†’ Allow with audit log entry
- Forecast not set for day â†’ actual_orders recorded, forecasted_orders = NULL, variance = NULL
- Multiple status changes in 1 second â†’ Only last update persists, all logged in audit

---

### Story 5.2: Build Desktop Navigation and Pipeline Overview (8 Stages)

As an operations manager,
I want to see a collapsible sidebar for navigation and a pipeline overview showing real-time order counts across all stages,
So that I can quickly understand order flow and navigate between sections.

**Acceptance Criteria:**

**Given** I am logged in as operations_manager or admin on desktop (â‰¥1280px width)
**When** I navigate to /operations-control
**Then** A collapsible sidebar displays on the left: Width: 70px collapsed (default), 250px expanded, Hover to expand (shows labels), Click to lock expanded state, Navigation items: ðŸ“Š Ops Control (current, highlighted in Tractis gold #e6c15c), ðŸ’° Business Dashboard, ðŸ“¦ Inventory, ðŸšš Fleet & Trucks, ðŸ‘¥ Team, ðŸ“ˆ Reports, âš™ï¸ Settings
**And** Main content area displays pipeline overview: Title: "Operations Control - [Operator Name]", 8 pipeline stage cards in responsive grid (all visible without scrolling on 1440px): Ingresado, Verificado, En Bodega, Asignado, En Carga, Listo, En Ruta, Entregado
**And** Each pipeline card shows: Stage name (Spanish), Large count number (e.g., "23"), Icon representing stage, Color coding: Red if urgent orders in stage, Yellow if alerts, Green if all ok, Click to filter orders table to this stage
**And** Real-time update: Counts refresh every 30 seconds via TanStack Query, Smooth count animation on change (count-up effect), Badge shows "Updated Xs ago"
**And** Sidebar state persists in localStorage (remains expanded/collapsed on page refresh)

**Edge Cases:**
- Narrow desktop (1280px-1440px) â†’ Sidebar auto-collapses, cards in 2x4 grid
- 0 orders in stage â†’ Show "0" in gray
- Network offline â†’ Show last cached counts with "Offline" indicator

---

### Story 5.3: Build Desktop Orders Table with Filters, Search, Live Updates

As an operations manager,
I want to see a detailed orders table with status, delivery promises, time windows, and filtering capabilities,
So that I can monitor specific orders and identify urgent items.

**Acceptance Criteria:**

**Given** I am viewing /operations-control on desktop below the pipeline overview
**When** The orders table loads
**Then** A table displays with columns: Status (ðŸ”´ðŸŸ¡ðŸŸ¢âš« indicator), Order # (clickable link), Cliente (retailer), Destino (comuna), Promesa (delivery promise date with smart display: "Hoy", "MaÃ±ana", "DD/MM"), Ventana (time window with countdown: "En 45 min", "En 2h 15m", "Pasado"), Estado (current pipeline_status), Acciones (reassign, view details buttons)
**And** Default sort: By time window countdown ascending (most urgent first)
**And** Status indicators: ðŸ”´ Urgent (red) if <45min to window, ðŸŸ¡ Alert (yellow) if 45min-2hr, ðŸŸ¢ OK (green) if >2hr, âš« Late (gray) if past deadline
**And** Clicking column header toggles sort (asc/desc) with visual indicator
**And** Top toolbar contains: Search input (searches order #, cliente, destino), Date filter dropdown (Hoy, MaÃ±ana, PrÃ³ximos 7 dÃ­as, Custom range), Status filter (All, Urgentes, Alertas, OK, Pasados), Pipeline stage filter (populated from sidebar card clicks), Clear filters button
**And** Pagination: 25 rows per page, "Load More" button at bottom (infinite scroll), Virtual scrolling if >100 orders for performance
**And** Clicking order # opens detail modal: Full order info, History timeline (status changes), Reassign to different zone button, Notes field
**And** Real-time updates: New orders appear at top with highlight animation, Status changes update in-place, Countdown timers decrement every minute

**Edge Cases:**
- >500 orders â†’ Virtual scrolling enabled, search becomes server-side
- Search no results â†’ Show empty state: "No orders match '[query]'"
- Time window passed while viewing â†’ Row color changes to gray, moves to bottom of list
- Filter combination returns 0 results â†’ Show "No orders match filters. Clear filters?"

---

### Story 5.4: Build Mobile Bottom Tab Navigation and Status Summary Cards

As an operations manager on mobile,
I want bottom tab navigation and status summary cards for quick access to urgent items,
So that I can monitor operations while away from my desk.

**Acceptance Criteria:**

**Given** I am logged in as operations_manager or admin on mobile (max-width 768px)
**When** I navigate to /operations-control on mobile
**Then** Mobile interface displays with: Header: "Ops Control" (updates based on active tab), Content area showing current tab content, Bottom tab bar (fixed at bottom, 60px from bottom edge for thumb reach)
**And** Bottom tab bar contains 5 tabs: ðŸ“Š Ops (active by default, highlighted in Tractis gold), ðŸ’° Dashboard, ðŸ“¦ Orders, ðŸ“ˆ Reports, âš™ï¸ More (settings, logout)
**And** Active tab styling: Gold background (#e6c15c), Scale animation on tap, Badge indicator (e.g., "3" on Ops tab for urgent items)
**And** Tapping tab switches content, updates header title, persists scroll position per tab
**And** Ops tab content displays status summary cards at top: Three cards in row: "Urgentes" (red, count of urgent orders), "Alertas" (yellow, count of alerts), "OK" (green, count of ok orders)
**And** Each status card shows: Large count, Status label, Tap to filter orders list to this status, Visual indicator (icon + color)
**And** Status cards update in real-time (30s refresh)

**Edge Cases:**
- Badge count >99 â†’ Display "99+"
- All statuses = 0 â†’ Show "No active orders" with illustration
- Tab switch during network request â†’ Cancel previous request, load new tab data

---

### Story 5.5: Build Mobile Orders List with Pull-to-Refresh

As an operations manager on mobile,
I want to see a card-based orders list optimized for touch with pull-to-refresh,
So that I can review orders on-the-go and get latest updates.

**Acceptance Criteria:**

**Given** I am on the Ops tab on mobile, below the status summary cards
**When** The orders list loads
**Then** Orders display as cards (not table) with: Order # (large, bold), Cliente + Comuna (secondary text), Delivery promise with countdown: "Hoy - En 45 min" (red if urgent), Pipeline status badge (colored chip), Large touch target (min 60px height), Swipe left reveals quick actions: "Ver detalles", "Reasignar"
**And** Default sort: Urgent orders first (red status), then alerts (yellow), then OK (green)
**And** Cards grouped by status with headers: "ðŸ”´ Urgentes (3)", "ðŸŸ¡ Alertas (12)", "ðŸŸ¢ OK (45)"
**And** Pull-to-refresh gesture (swipe down from top): Shows loading spinner, Fetches latest data from server, Animates content refresh, Shows toast: "Updated Xs ago"
**And** Infinite scroll: Loads 20 orders initially, "Load More" button loads next 20, Lazy loading as user scrolls
**And** Search input at top (collapsible): Tap to expand, searches order # and cliente, Shows results count: "3 results for 'Falabella'"
**And** Filter button opens modal with: Status checkboxes, Date range picker, Pipeline stage selector, Apply/Clear buttons

**Edge Cases:**
- Pull-to-refresh while offline â†’ Show cached data with "Offline" message
- No orders for selected filters â†’ Show empty state: "No orders match filters"
- Rapid scroll â†’ Debounce load more to prevent duplicate requests
- Swipe gesture conflicts with browser back â†’ Disable horizontal swipe gestures

---

### Story 5.6: Implement Capacity Alerts and Forecast Accuracy Tracking

As an operations manager,
I want to receive automated alerts when retailers approach capacity limits and see forecast accuracy,
So that I can proactively plan resources and avoid being overwhelmed.

**Acceptance Criteria:**

**Given** Capacity forecasts exist in the database for retailers
**When** Daily order ingestion occurs
**Then** System calculates capacity utilization: For each retailer on each day: actual_orders / forecasted_orders * 100 = utilization_percentage
**And** Automated alerts trigger when: â‰¥80% of forecast reached â†’ Email + in-app notification: "Falabella approaching capacity (278/300 orders, 93%)", â‰¥100% of forecast reached â†’ Urgent alert: "Falabella EXCEEDED capacity (347/300 orders, 116%)", â‰¥120% of forecast â†’ Critical alert with SMS: "Falabella at 140% capacity (420/300). Immediate action required."
**And** Alert recipients: Operations managers for the operator, Aureon DevOps (for platform-wide capacity monitoring)
**And** In-app notifications display: Alert bell icon (badge count), Notification panel slides from right, List of alerts with: Timestamp, severity color, retailer name, utilization %, "Dismiss" and "View Details" buttons
**And** /capacity-planning page shows: Table of retailers with forecasted vs actual orders, Color-coded utilization: Green <80%, Yellow 80-100%, Orange 100-120%, Red >120%, Forecast accuracy trend chart (last 30 days): Line chart showing predicted vs actual variance, Retailer ranking by accuracy (best/worst forecasters)
**And** Forecast accuracy calculation: For each retailer: variance = abs(forecasted - actual) / forecasted * 100, Accuracy score = 100 - avg(variance) over last 30 days

**Edge Cases:**
- No forecast set for retailer â†’ No alerts triggered, capacity page shows "N/A"
- Forecast = 0 â†’ Treat as "no forecast", don't calculate utilization
- Alert fatigue (multiple alerts per day) â†’ Group by retailer, send digest once per day
- SMS rate limit exceeded â†’ Fallback to email only

---

### Story 5.7: Build Audit Log Viewer with Search and Filters

As an operations manager,
I want to search and filter audit logs to troubleshoot operational issues,
So that I can investigate what happened and when.

**Acceptance Criteria:**

**Given** Audit logs exist from Epic 1 Story 1.6
**When** I navigate to /audit-logs (admin or operations_manager only)
**Then** An audit log viewer displays with: Table columns: Timestamp (sortable), User (full name + role), Action (e.g., "SCAN_ORDER", "CREATE_USER"), Resource (type + ID link), Details (expandable JSON), IP Address
**And** Default sort: By timestamp descending (newest first)
**And** Search and filter toolbar: Date range picker (default: last 7 days), User dropdown (all users in operator), Action type dropdown (all action types), Resource type dropdown (order, manifest, user, etc.), Search input (searches resource ID, action details), "Export CSV" button
**And** Table pagination: 50 logs per page, Virtual scrolling if >500 logs
**And** Clicking resource ID opens detail: For orders â†’ Order detail page, For manifests â†’ Manifest summary, For users â†’ User profile
**And** Expandable details row: Click row to expand, Shows full changes_json in formatted view, Before/after comparison for UPDATE actions, Syntax highlighting for JSON
**And** Real-time updates: New audit entries appear at top with highlight, Badge shows "X new logs" with refresh button
**And** Export CSV includes: All visible columns, Current filters applied, Date range in filename: "audit-logs-2026-02-07.csv"

**Edge Cases:**
- >10,000 logs in date range â†’ Server-side pagination required, show warning: "Large date range. Consider narrowing filters."
- changes_json is huge (>100KB) â†’ Truncate display, show "View Full JSON" button that opens modal
- Search no results â†’ Show empty state: "No logs match search criteria"
- Non-admin user â†’ Only see logs for actions they performed (filtered by user_id automatically)

---

### Story 5.8: Set Up Platform Health Monitoring Dashboard (Aureon DevOps)

As an Aureon DevOps engineer,
I want a platform health monitoring dashboard showing uptime, performance, and customer usage across all operators,
So that I can proactively identify issues and scale resources.

**Acceptance Criteria:**

**Given** I am logged in with an Aureon DevOps account (special role)
**When** I navigate to /devops/platform-health
**Then** Platform health dashboard displays: System status overview: Vercel (frontend) status: âœ… Up / ðŸ”´ Down, Railway (backend) status: âœ… Up / ðŸ”´ Down, Supabase (database) status: âœ… Up / ðŸ”´ Down, n8n (workflows) status: âœ… Up / ðŸ”´ Down, BetterStack uptime: 99.97% (last 30 days)
**And** Performance metrics section: API response times: Line chart (last 24 hours), p50, p95, p99 percentiles, Current: p95 = 287ms (green if <500ms, yellow if 500ms-1s, red if >1s), Error rate: Percentage of failed requests (last 24 hours), Current: 0.3% (green if <1%, yellow if 1-5%, red if >5%), Database connections: Current connections / max connections, Current: 47/100 (yellow if >80%, red if >90%), CPU & Memory: Railway backend CPU usage, Vercel Edge function invocations
**And** Customer usage analytics table: Columns: Operator Name, Active Users (last 7 days), Total Orders (month), API Calls (last 24h), Subscription Tier, Usage vs. Limit
**And** Sort by any column (default: by API calls descending)
**And** Alerts configuration section: Current alert rules displayed, "Add Alert" button opens modal to create new alert, Example: "API p95 > 1s for 5 minutes â†’ Email devops@aureon.com"
**And** Infrastructure scaling controls: Button: "Add Database Replica", Button: "Scale API Servers" (shows current count + add/remove), Button: "Invalidate CDN Cache"

**Technical Requirements:**
- Integrate with Vercel Analytics API
- Integrate with Railway Metrics API
- Integrate with Supabase Dashboard API
- Integrate with BetterStack API

**Edge Cases:**
- External service API unavailable â†’ Show last cached value with "Data stale" indicator
- Alert rule triggers â†’ Send email + log to audit_logs
- Scaling action fails â†’ Show error toast with rollback option

---

### Story 5.9: Configure Supabase Realtime for Live Order Updates

As an operations manager,
I want order status changes to appear instantly on my dashboard without refreshing,
So that I always see the current state without manual reloads.

**Acceptance Criteria:**

**Given** Supabase Realtime is enabled on the orders and manifests tables
**When** An order status changes (via any source: API, manual update, background job)
**Then** Supabase broadcasts the change to all subscribed clients via WebSocket
**And** Frontend subscribes to realtime channel on /operations-control page load: Channel: `operator:[operator_id]:orders`, Listen for: INSERT, UPDATE, DELETE events on orders table
**And** On INSERT event (new order): Toast notification: "New order received: #[order_number]", Order appears at top of list with highlight animation, Pipeline count increments (+1 in "Ingresado" card), Play subtle notification sound (if enabled)
**And** On UPDATE event (status change): Affected order row updates in-place (no full page reload), Pipeline counts adjust (decrement old status, increment new status), If status changes to urgent â†’ Show alert toast: "Order #12345 now URGENT", If order is currently filtered out â†’ Remove from view (smooth fade out)
**And** On DELETE event (order cancelled/deleted): Order row fades out and removes from list, Pipeline count decrements, Toast: "Order #[order_number] cancelled"
**And** Realtime connection status indicator: Green dot in header when connected, Red dot with "Disconnected" when WebSocket drops, Auto-reconnect attempts with exponential backoff
**And** Fallback: If Realtime disconnects for >30s, fall back to TanStack Query polling (every 30s)

**Technical Requirements:**
- Use Supabase Realtime JavaScript client
- Subscribe on component mount, unsubscribe on unmount
- Handle reconnection logic
- Debounce rapid updates (max 1 update per second per order)

**Edge Cases:**
- Realtime quota exceeded (free tier limit) â†’ Fall back to polling permanently, show warning
- Mass update (100+ orders at once) â†’ Batch UI updates, show summary toast: "100 orders updated"
- User on different tab â†’ Queue updates, apply when tab becomes active
- WebSocket blocked by firewall â†’ Graceful fallback to HTTP polling
